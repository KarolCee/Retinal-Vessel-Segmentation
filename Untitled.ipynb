{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image processing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import frangi\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.exposure import equalize_adapthist\n",
    "from skimage.morphology import binary_erosion,binary_dilation\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "#ML\n",
    "from skimage.measure import moments_central, moments_normalized, moments_hu\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import pickle #model save\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating images with highlighted vessels using basic image processing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [ '14_dr.JPG','14_g.JPG','14_h.JPG','15_dr.JPG','15_g.JPG','15_h.JPG']\n",
    "manual_test_images = [ '14_dr.tif','14_g.tif','14_h.tif','15_dr.tif','15_g.tif','15_h.tif']\n",
    "test_masks = [ '14_dr_mask.tif','14_g_mask.tif','14_h_mask.tif','15_dr_mask.tif','15_g_mask.tif','15_h_mask.tif']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,15))\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "props = dict(facecolor='wheat', alpha=0.6)\n",
    "fig.tight_layout()  \n",
    "\n",
    "\n",
    "for image_name, manual_image_name, mask_name in zip(test_images,manual_test_images,test_masks):\n",
    "    \n",
    "    #ground truth - just for comparison\n",
    "    manual_test_image = rgb2gray(io.imread('HRF/manual1/' + manual_image_name))/255\n",
    "    #mask\n",
    "    test_mask = rgb2gray(io.imread('HRF/mask/' + mask_name ))\n",
    "    \n",
    "    \n",
    "    #image for testing\n",
    "    test_image = equalize_adapthist(gaussian(io.imread('HRF/images/' + image_name)[:,:,1]/255))\n",
    "    #EDGE DETECTION\n",
    "    test_image = frangi(test_image)*test_mask\n",
    "    # binarization\n",
    "    adaptive_thresh = threshold_local(test_image,2001)\n",
    "    binary_adaptive = test_image > adaptive_thresh\n",
    "    test_image = binary_erosion(binary_adaptive,selem=np.ones((3,3)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #images for showing the results from ground truth and the algorithm\n",
    "    manual_image_save = io.imread('HRF/images/' + image_name)\n",
    "    image_save = io.imread('HRF/images/' + image_name)\n",
    "    \n",
    "    #Positive = vessel, Negative = background\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    Sensitivity = 0.0\n",
    "    Specificity = 0.0\n",
    "    Accuracy = 0.0\n",
    "\n",
    "    for y in range(len(test_image)):\n",
    "        for x in range(len(test_image[0])):\n",
    "            #highlight found vessels\n",
    "            if(test_image[y,x]>0 and manual_test_image[y,x]>0):\n",
    "                image_save[y,x,0:4] = 255\n",
    "                manual_image_save[y,x,0:4] = 255\n",
    "                TP+=1\n",
    "            elif(test_image[y,x]==0 and manual_test_image[y,x]==0):\n",
    "                TN+=1\n",
    "            elif(test_image[y,x]>0 and manual_test_image[y,x]==0):\n",
    "                image_save[y,x,0:4] = 255\n",
    "                FP+=1\n",
    "            elif(test_image[y,x]==0 and manual_test_image[y,x]>0):\n",
    "                FN+=1\n",
    "                manual_image_save[y,x,0:4] = 255\n",
    "    \n",
    "    print('wyliczam statystyki')\n",
    "    Sensitivity = TP/(TP + FN)\n",
    "    Specificity = TN/(TN+FP)\n",
    "    Accuracy = (TN + TP)/(TN+TP+FN+FP)\n",
    "    GM = (Sensitivity*Specificity)**(0.5)\n",
    "    statistics = \"\"\n",
    "    statistics += f'TP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\\n'\n",
    "    statistics += f'Accuracy: {Accuracy}\\nSpecificity: {Specificity}\\nSensitivity: {Sensitivity}\\n'\n",
    "    statistics += f'GM: {GM}'\n",
    "    \n",
    "    ax[0].imshow(manual_image_save)\n",
    "    ax[1].imshow(image_save)\n",
    "    textVar = ax[1].text(0,0, statistics,verticalalignment='top', bbox=props, fontsize = 14)\n",
    "    \n",
    "    fig.savefig('results_image_processing/' + image_name, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    textVar.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and saving model for further testing (also tuning k parameter for KNN classifier with k-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pixels_num = 200000 #number of pixels for each image to train on\n",
    "\n",
    "# RETINAL IMAGES\n",
    "train_images = ['01_dr.JPG','01_g.JPG','01_h.JPG',\n",
    "                '02_dr.JPG','02_g.JPG','02_h.JPG',\n",
    "                '03_dr.JPG','03_g.JPG','03_h.JPG',\n",
    "                '04_dr.JPG','04_g.JPG','04_h.JPG',\n",
    "                '05_dr.JPG','05_g.JPG','05_h.JPG',\n",
    "                '06_dr.JPG','06_g.JPG','06_h.JPG',\n",
    "                '07_dr.JPG','07_g.JPG','07_h.JPG',\n",
    "                '08_dr.JPG','08_g.JPG','08_h.JPG',\n",
    "                '09_dr.JPG','09_g.JPG','09_h.JPG',\n",
    "                '10_dr.JPG','10_g.JPG','10_h.JPG',\n",
    "                '11_dr.JPG','11_g.JPG','11_h.JPG',\n",
    "                '12_dr.JPG','12_g.JPG','12_h.JPG',\n",
    "                '13_dr.JPG','13_g.JPG','13_h.JPG']\n",
    "#GROUND TRUTH                \n",
    "manual_train_images = [ '01_dr.tif','01_g.tif','01_h.tif',\n",
    "                        '02_dr.tif','02_g.tif','02_h.tif',\n",
    "                        '03_dr.tif','03_g.tif','03_h.tif',\n",
    "                        '04_dr.tif','04_g.tif','04_h.tif',\n",
    "                        '05_dr.tif','05_g.tif','05_h.tif',\n",
    "                        '06_dr.tif','06_g.tif','06_h.tif',\n",
    "                        '07_dr.tif','07_g.tif','07_h.tif',\n",
    "                        '08_dr.tif','08_g.tif','08_h.tif',\n",
    "                        '09_dr.tif','09_g.tif','09_h.tif',\n",
    "                        '10_dr.tif','10_g.tif','10_h.tif',\n",
    "                        '11_dr.tif','11_g.tif','11_h.tif',\n",
    "                        '12_dr.tif','12_g.tif','12_h.tif',\n",
    "                        '13_dr.tif','13_g.tif','13_h.tif']\n",
    "\n",
    "\n",
    "X = np.zeros((random_pixels_num*len(train_images),7)) #7 features = 7 hu moments\n",
    "y = np.zeros(random_pixels_num*len(train_images))\n",
    "\n",
    "\n",
    "k_range = range(3,16,3)\n",
    "k_scores = []\n",
    "\n",
    "\n",
    "#creating training dataset\n",
    "counter = 0\n",
    "for m, i in zip(manual_train_images,train_images):\n",
    "    manual_train_image = rgb2gray(io.imread('HRF/manual1/' + m))/255\n",
    "    train_image = equalize_adapthist(gaussian(io.imread('HRF/images/' + i)[:,:,1]/255))\n",
    "    #each image has a number of random pixels to train on\n",
    "    for z in range(random_pixels_num):\n",
    "        x_coord = random.randint(2,len(train_image[0])-3)\n",
    "        y_coord = random.randint(2,len(train_image)-3)\n",
    "        # 5x5 neighbour pixels for features extraction\n",
    "        image_part = train_image[y_coord-2:y_coord+3,x_coord-2:x_coord+3]\n",
    "        mu = moments_central(image_part)\n",
    "        nu = moments_normalized(mu)\n",
    "        features = moments_hu(nu)\n",
    "        # 7 features for each pixel\n",
    "        X[counter][:] = features\n",
    "        #decision feature 0 = no vessel, 1 = vessel\n",
    "        y[counter] = int(manual_train_image[y_coord][x_coord])\n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "print(\"dataset created\")\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'X shape: {X.shape}')\n",
    "#parameter k tuning with kfold validation\n",
    "for k in k_range:\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    kfold = StratifiedKFold(n_splits=10)\n",
    "    print(f\"wyliczam accuracy dla k: {k}\")\n",
    "    cv_results = cross_val_score(neigh, X, y, cv=kfold, scoring='accuracy')\n",
    "    k_scores.append(cv_results.mean())\n",
    "\n",
    "k_index = k_scores.index(max(k_scores))\n",
    "k_chosen = k_range[k_index]\n",
    "print(f'wybrane k = {k_chosen}')\n",
    "print(f'max acc = {k_scores[k_index]}')\n",
    "\n",
    "\n",
    "#save plot showing mean accuracy for each k value\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('K value')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.savefig('K_values.png')\n",
    "\n",
    "#fit final model with the best k value\n",
    "neigh = KNeighborsClassifier(n_neighbors=k_chosen)\n",
    "neigh.fit(X, y)\n",
    "\n",
    "#save trained model for further testing\n",
    "with open('finalized_model.sav', \"wb\") as f:\n",
    "    pickle.dump(neigh, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the model that we created above and creating images with highlighted vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = ['14_dr.JPG','14_g.JPG','14_h.JPG','15_dr.JPG','15_g.JPG','15_h.JPG']\n",
    "                \n",
    "manual_test_images = ['14_dr.tif','14_g.tif','14_h.tif','15_dr.tif','15_g.tif','15_h.tif']\n",
    "\n",
    "\n",
    "\n",
    "#fmake a fig to save results\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,15))\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "props = dict(facecolor='wheat', alpha=0.6)\n",
    "fig.tight_layout()  \n",
    "\n",
    "#load the model made before\n",
    "with open('finalized_model.sav', \"rb\") as f:\n",
    "    neigh = pickle.load(f)\n",
    "    \n",
    "\n",
    "print(\"START\")\n",
    "for image_name, manual_image_name in zip(test_images,manual_test_images):\n",
    "    \n",
    "    #ground truth - just for comparison\n",
    "    manual_test_image = rgb2gray(io.imread('HRF/manual1/' + manual_image_name))/255\n",
    "    #image for testing\n",
    "    test_image = equalize_adapthist(gaussian(io.imread('HRF/images/' + image_name)[:,:,1]/255))\n",
    "    #images for showing the results from ground truth and the algorithm\n",
    "    manual_image_save = io.imread('HRF/images/' + image_name)\n",
    "    image_save = io.imread('HRF/images/' + image_name)\n",
    "    \n",
    "    #Positive = vessel, Negative = background\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    Sensitivity = 0.0\n",
    "    Specificity = 0.0\n",
    "    Accuracy = 0.0\n",
    "\n",
    "    for y in range(2,len(test_image)-2):\n",
    "        for x in range(2,len(test_image[0])-2):\n",
    "            image_part = test_image[y-2:y+3,x-2:x+3]\n",
    "            mu = moments_central(image_part)\n",
    "            nu = moments_normalized(mu)\n",
    "            features = moments_hu(nu)\n",
    "            y_predicted = neigh.predict([features])\n",
    "            \n",
    "            #highlight found vessels\n",
    "            if(y_predicted[0]>0 and manual_test_image[y,x]>0):\n",
    "                image_save[y,x,0:4] = 255\n",
    "                manual_image_save[y,x,0:4] = 255\n",
    "                TP+=1\n",
    "            elif(y_predicted[0]==0 and manual_test_image[y,x]==0):\n",
    "                TN+=1\n",
    "            elif(y_predicted[0]>0 and manual_test_image[y,x]==0):\n",
    "                image_save[y,x,0:4] = 255\n",
    "                FP+=1\n",
    "            elif(y_predicted[0]==0 and manual_test_image[y,x]>0):\n",
    "                FN+=1\n",
    "                manual_image_save[y,x,0:4] = 255\n",
    "    \n",
    "    print('wyliczam statystyki')\n",
    "    Sensitivity = TP/(TP + FN)\n",
    "    Specificity = TN/(TN+FP)\n",
    "    Accuracy = (TN + TP)/(TN+TP+FN+FP)\n",
    "    GM = (Sensitivity*Specificity)**(0.5)\n",
    "    statistics = \"\"\n",
    "    statistics += f'TP: {TP}\\nTN: {TN}\\nFP: {FP}\\nFN: {FN}\\n'\n",
    "    statistics += f'Accuracy: {Accuracy}\\nSpecificity: {Specificity}\\nSensitivity: {Sensitivity}\\n'\n",
    "    statistics += f'GM: {GM}'\n",
    "    \n",
    "    ax[0].imshow(manual_image_save)\n",
    "    ax[1].imshow(image_save)\n",
    "    textVar = ax[1].text(0,0, statistics,verticalalignment='top', bbox=props, fontsize = 14)\n",
    "    \n",
    "    fig.savefig('results_machine_learning/' + image_name, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    textVar.set_visible(False)    \n",
    "    \n",
    "            \n",
    "\n",
    "print(\"FINISH\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
